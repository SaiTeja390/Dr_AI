{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"Dr_AI_ICD_3.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cYrAoG822PV6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFRD7HcxwSEG","colab_type":"code","outputId":"a2866ea2-2b1c-4f1e-decc-df55a07dfe5a","executionInfo":{"status":"ok","timestamp":1583313787626,"user_tz":-330,"elapsed":8571,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":216}},"source":["!pip install --upgrade tables"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tables\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n","\u001b[K     |████████████████████████████████| 4.3MB 703kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.17.5)\n","Requirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n","Installing collected packages: tables\n","  Found existing installation: tables 3.4.4\n","    Uninstalling tables-3.4.4:\n","      Successfully uninstalled tables-3.4.4\n","Successfully installed tables-3.6.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DOpikSXbsvn-","colab_type":"code","outputId":"b515b0f9-f6aa-4caa-fd6c-f0bf5c9af15b","executionInfo":{"status":"ok","timestamp":1583313807939,"user_tz":-330,"elapsed":27090,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["\n","\n","\n","# Upload the train file from your local drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fpxBMJWyiXZH","colab_type":"code","outputId":"37c9da77-9252-45f0-b9c8-15491df69f44","executionInfo":{"status":"ok","timestamp":1583313807942,"user_tz":-330,"elapsed":25657,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd /content/drive/My\\ Drive/Dr_AI\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Dr_AI\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.113315Z","start_time":"2020-03-01T08:07:17.375425Z"},"id":"AkF_9Hnz2K_H","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import torch \n","from torch import nn\n","\n","\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchtext.data import Field, Dataset, Example\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score,hamming_loss\n","\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.122761Z","start_time":"2020-03-01T08:07:18.114589Z"},"id":"N7fObNQF2K_m","colab_type":"code","colab":{}},"source":["# loading\n","with open('tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.310131Z","start_time":"2020-03-01T08:07:18.124438Z"},"id":"nug3kw0i2K_-","colab_type":"code","colab":{}},"source":["tokenizer.sequences_to_texts([[1,2,3]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.513597Z","start_time":"2020-03-01T08:07:18.311382Z"},"id":"4ttNA7_h2LAT","colab_type":"code","colab":{}},"source":["\n","class DataFrameDataset(Dataset):\n"," \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n","#  def __init__(self, fields, path='./test1.h5', filter_pred=None):\n"," def __init__(self, fields, examples, filter_pred=None): \n","    \"\"\"\n","     Create a dataset from a pandas dataframe of examples and Fields\n","     Arguments:\n","         examples pd.DataFrame: DataFrame of examples\n","         fields {str: Field}: The Fields to use in this tuple. The\n","             string is a field name, and the Field is the associated field.\n","         filter_pred (callable or None): use only exanples for which\n","             filter_pred(example) is true, or use all examples if None.\n","             Default is None\n","    \"\"\"\n","#     examples = pd.read_hdf(path)\n","    self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n","    if filter_pred is not None:\n","         self.examples = filter(filter_pred, self.examples)\n","    self.fields = dict(fields)\n","     # Unpack field tuples\n","    for n, f in list(self.fields.items()):\n","         if isinstance(n, tuple):\n","            self.fields.update(zip(n, f))\n","            del self.fields[n]\n","\n","class SeriesExample(Example):\n","    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n","\n","    @classmethod \n","    def fromSeries(cls, data, fields):\n","        return cls.fromdict(data.to_dict(), fields)\n","\n","    @classmethod\n","    def fromdict(cls, data, fields):\n","        ex = cls()\n","        fields = dict(fields)\n","#         print(fields.items())\n","        for key, field in fields.items():\n","#             print(key)\n","            if key not in data:\n","                 raise ValueError(\"Specified key {} was not found in \"\n","         \"the input data\".format(key))\n","            if field is not None:\n","                setattr(ex, key, field.preprocess(data[key]))\n","#                 print(field.preprocess(data[key]))   \n","            else:\n","                 setattr(ex, key, data[key])\n","#         print(ex.input.pad_)        \n","        return ex"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.691871Z","start_time":"2020-03-01T08:07:18.514827Z"},"id":"Bvxh7cfC2LAj","colab_type":"code","colab":{}},"source":["# LABEL = Field(sequential=True,use_vocab=False,batch_first=True,pad_token=[0]*4386)\n","# INPUT = Field(sequential=True,use_vocab=False,batch_first=True,pad_token=[0]*1364)\n","# LENGTH = Field(sequential=False,use_vocab=False,batch_first=True,pad_token=0)\n","\n","\n","LABEL = Field(sequential=True,use_vocab=False,batch_first=True,pad_token=[0]*2806)\n","INPUT = Field(sequential=True,use_vocab=False,batch_first=True,pad_token=[0]*1343)\n","LENGTH = Field(sequential=False,use_vocab=False,batch_first=True,pad_token=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.933803Z","start_time":"2020-03-01T08:07:18.693071Z"},"id":"0vMAyTYM2LA1","colab_type":"code","colab":{}},"source":["fields = [('label',LABEL),('input',INPUT),('length',LENGTH)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:22.834239Z","start_time":"2020-03-01T08:07:18.935547Z"},"id":"CPFGfX8i2LBD","colab_type":"code","colab":{}},"source":["# final_df2 = pd.read_hdf('./test_ICD.h5')\n","final_df2 = pd.read_hdf('./m_test.h5')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.691871Z","start_time":"2020-03-01T08:07:18.514827Z"},"id":"OE54StoewHet","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:22.834239Z","start_time":"2020-03-01T08:07:18.935547Z"},"id":"O9mNpNdwwHfM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"brnBDQKg4pQo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:22.839056Z","start_time":"2020-03-01T08:07:22.835589Z"},"id":"KPmq49LR2LBP","colab_type":"code","colab":{}},"source":["final_df2.columns\n","final_df2 = final_df2.rename({'labels':'label', 'lengths':'length'},axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:23.367072Z","start_time":"2020-03-01T08:07:22.840536Z"},"id":"w5UEwwV32LBe","colab_type":"code","colab":{}},"source":["train, test = train_test_split(final_df2, test_size=0.1)\n","train, val = train_test_split(train, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:28.389256Z","start_time":"2020-03-01T08:07:23.368277Z"},"id":"HyFtBMc12LBq","colab_type":"code","colab":{}},"source":["train_ds = DataFrameDataset(fields, train)\n","val_ds = DataFrameDataset(fields, val)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:28.890064Z","start_time":"2020-03-01T08:07:28.390696Z"},"id":"zGi7skyq2LB_","colab_type":"code","colab":{}},"source":["test_ds = DataFrameDataset(fields=fields, examples=test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:28.893843Z","start_time":"2020-03-01T08:07:28.891496Z"},"id":"2ZlbpZp62LCR","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"," \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DAHH9NA2LCd","colab_type":"code","colab":{}},"source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:29.008103Z","start_time":"2020-03-01T08:07:28.895094Z"},"id":"Vy3XSvF12LCo","colab_type":"code","colab":{}},"source":["from torchtext.data import Iterator, BucketIterator\n","\n","train_iter, val_iter, test_iter = BucketIterator.splits(\n"," (train_ds,val_ds,test_ds), # we pass in the datasets we want the iterator to draw data from\n"," batch_sizes=(BATCH_SIZE, BATCH_SIZE,BATCH_SIZE),\n"," device=device, # if you want to use the GPU, specify the GPU number here\n"," sort_key=lambda x: x.length, # the BucketIterator needs to be told what function it should use to group the data.\n"," sort_within_batch=True,\n"," repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",")\n","# test_iter = Iterator(tst, batch_size=64, device=-1, sort=False, sort_within_batch=False, repeat=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dFJ3NNbC2LCz","colab_type":"code","colab":{}},"source":["# for batch in train_iter:\n","#     print(f'{batch.input[0]}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:29.137863Z","start_time":"2020-03-01T08:07:29.009389Z"},"id":"fd6CMQ6N2LC8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:08:15.418062Z","start_time":"2020-03-01T08:08:15.408738Z"},"id":"CmNnnP1x2LDG","colab_type":"code","colab":{}},"source":["class GRUNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, num_emd, drop_prob=0.2, wv_file=None, tokenizer=None ):\n","        super(GRUNet, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","        self.drop_prob = drop_prob\n","\n","        self.embedding = nn.Embedding(embedding_dim=input_dim, num_embeddings=num_emd, padding_idx=0)\n","        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.sigmoid = nn.Sigmoid()\n","        self.wv_file =  wv_file\n","        self.tokenizer = tokenizer\n","        \n","    def forward(self, x,length):\n","        out = self.embedding(x)\n","#         print(f'before sum {out.shape}')\n","\n","        out = out.sum(dim=-2)\n","        # print(f'before packing {out.shape} ')\n","        out = torch.nn.utils.rnn.pack_padded_sequence(out, lengths=length, batch_first=True, enforce_sorted=True)\n","        # print(f'after packing {out.data.shape}  {out.batch_sizes} {length} {out}')\n","           \n","        packed_output, h = self.gru(out)\n","        out, out_lengths = torch.nn.utils.rnn.pad_packed_sequence(packed_output)\n","#         print(f'after unpacking {out.shape} {out_lengths.shape}')\n","        out = out.transpose(0,1)\n","        out = self.fc(out)\n","\n","        out=self.sigmoid(out)\n","        return out, h\n","    \n","    def init_weights( self, batch_size):\n","        \n","      if self.wv_file:\n","          print(self.wv_file)\n","          from gensim.models import KeyedVectors, Word2Vec\n","\n","          wv = KeyedVectors.load(self.wv_file)\n","          word_indexer  = self.tokenizer.word_index\n","          \n","          wv_2 = {}\n","\n","          for word in word_indexer:\n","              try:\n","                  wv_2[word_indexer[word]]= wv[word]\n","              except KeyError as k:\n","                  wv_2[word_indexer[word]] = np.zeros(wv.vector_size)\n","\n","          wv_2\n","          x = [v for k, v in sorted(wv_2.items(), key=lambda item: item[0], reverse=False)]\n","\n","          pad = np.zeros_like(x[0])\n","          x.insert(0,pad)\n","          y = torch.tensor(x, dtype=torch.float32)\n","          print(f'y  {y.shape}')\n","          device = self.embedding.weight.device\n","          self.embedding.weight =  torch.nn.Parameter(y)\n","          self.embedding = self.embedding.to(device)\n","          self.gru = nn.GRU(wv.vector_size, self.hidden_dim, self.n_layers, batch_first=True, dropout=self.drop_prob).to(device)\n","\n","      self.init_hidden(batch_size)\n","\n","          \n","    def init_hidden(self, batch_size ):\n","        weight = next(self.parameters()).data\n","        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:06:32.682179Z","start_time":"2020-03-01T08:06:32.462360Z"},"id":"DhPkMQNo2LDR","colab_type":"code","colab":{}},"source":["# model = GRUNet(input_dim=1000, hidden_dim=2000, output_dim=4386, n_layers=2, num_emd=8200 )\n","  model = GRUNet(input_dim=1000, hidden_dim=2000, output_dim=2806, n_layers=2, num_emd=8200)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:55.233905Z","start_time":"2020-03-01T06:01:55.229523Z"},"id":"2cf6qnb52LDZ","colab_type":"code","outputId":"6e0c6a9c-ab3d-40a2-ca5c-28fc1d1a0a9f","executionInfo":{"status":"ok","timestamp":1583313990711,"user_tz":-330,"elapsed":1859,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":30,"outputs":[{"output_type":"stream","text":["The model has 55,838,806 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:55.460640Z","start_time":"2020-03-01T06:01:55.458502Z"},"id":"SeEd2Gp62LDl","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters(),weight_decay=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:55.669349Z","start_time":"2020-03-01T06:01:55.666150Z"},"id":"Ffxz6J_b2LDu","colab_type":"code","colab":{}},"source":["criterion = nn.BCELoss()\n","# criterion = nn.CrossEntropyLoss()\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:55.879342Z","start_time":"2020-03-01T06:01:55.874584Z"},"id":"Y80qlQix2LD5","colab_type":"code","colab":{}},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:56.109494Z","start_time":"2020-03-01T06:01:56.106412Z"},"id":"EBUGgmwJ2LEE","colab_type":"code","colab":{}},"source":["def compute_loss(model, iterator, criterion):\n","    loss = 0\n","    \n","    for batch in iterator:\n","        text = batch.input\n","        text_lengths = batch.length\n","\n","        predictions,h = model(text, text_lengths)\n","#         print(f'predictions.shape {predictions}')\n","#         print(f'\\n\\n labels \\n{batch.label.dtype} \\n\\n predictions\\n {predictions.dtype}')\n","        label = batch.label.to(dtype=torch.float32)\n","        loss += criterion(predictions, label).item()\n","    return loss/len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:56.316722Z","start_time":"2020-03-01T06:01:56.314915Z"},"id":"3xwQ4V1L2LEM","colab_type":"code","colab":{}},"source":["k = 30"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:56.530840Z","start_time":"2020-03-01T06:01:56.524307Z"},"id":"jW-d3fw52LEW","colab_type":"code","colab":{}},"source":["def ham_loss(model, iterator, k=60):\n","    acc = 0\n","    n_samples = 0\n","    recall = []\n","    \n","    for batch in iterator:\n","        text = batch.input\n","        text_lengths = batch.length\n","\n","        predictions,h = model(text, text_lengths)\n","        predictions = (predictions.detach().cpu().numpy()).reshape(predictions.shape[0]*predictions.shape[1],-1)\n","        labels = np.array(batch.label.cpu()).reshape(batch.label.shape[0]*batch.label.shape[1],-1)\n","        \n","#         pred_seq = [np.where(x[0]==1)[0] for x in predictions]\n","        label_seq = [np.where(x==1)[0] for x in labels]\n","#         predictions = predictions.reshape(predictions.shape[0]*predictions.shape[1],-1)\n","        try :    \n","            for p,q in zip(label_seq,predictions):\n","                pred =np.sort(np.argsort(q)[-k:])\n","                acc += (np.intersect1d(pred,p)).size\n","                n_samples+=(p.size)   \n","                rec = (np.intersect1d(pred,p)).size/p.size\n","                recall.append(rec)\n","    #             print(acc)\n","    #             print(n_samples, len(p))\n","    #         acc += np.sum(np.not_equal(pred_seq, label_seq))\n","        except ZeroDivisionError as z:\n","            continue\n","        \n","    return(np.mean(recall))       "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:56.751416Z","start_time":"2020-03-01T06:01:56.748717Z"},"id":"r5q7ZzJ72LEd","colab_type":"code","outputId":"7c3e2fec-e00a-4852-b110-1ca8e9488922","executionInfo":{"status":"ok","timestamp":1583313993037,"user_tz":-330,"elapsed":1289,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["model"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GRUNet(\n","  (embedding): Embedding(8200, 1000, padding_idx=0)\n","  (gru): GRU(1000, 2000, num_layers=2, batch_first=True, dropout=0.2)\n","  (fc): Linear(in_features=2000, out_features=2806, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:57.255966Z","start_time":"2020-03-01T06:01:56.948065Z"},"id":"k1TFeC162LEn","colab_type":"code","outputId":"84879d31-cce1-41a2-9db5-44a5d893a099","executionInfo":{"status":"ok","timestamp":1583314005364,"user_tz":-330,"elapsed":8695,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["print(f'train {ham_loss(model=model,iterator=train_iter)} \\n\\n val {ham_loss(model=model,iterator=val_iter)}')\n","ham_loss(model=model,iterator=test_iter, k=100)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["train 0.02292466404101867 \n","\n"," val 0.02203229313942063\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.03859723546247425"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:33.271536Z","start_time":"2020-03-01T06:02:33.260383Z"},"id":"rwlkyPo32LEw","colab_type":"code","colab":{}},"source":["\n","\n","def train(model, train_iterator, optimizer, criterion, val_iterator,epochs=100):\n","    \n","    metrics = []\n","    epoch_loss = 0\n","    val_loss = 0\n","    \n","    model.train()\n","    h = model.init_weights(batch_size=BATCH_SIZE)\n","\n","    for epoch in range(epochs):  \n","        epoch_loss = 0\n","        for batch in train_iterator:\n","\n","            optimizer.zero_grad()\n","\n","            text = batch.input\n","            text_lengths = batch.length\n","            # print(text)\n","            predictions,h = model(text, text_lengths)\n","            # print(f'predictions.shape {predictions}')\n","    #         print(f'\\n\\n labels \\n{batch.label.dtype} \\n\\n predictions\\n {predictions.dtype}')\n","            label = batch.label.to(dtype=torch.float32)\n","            # print(f'{predictions.shape} {label.shape}')\n","            loss = criterion(predictions, label)\n","    #         acc = binary_accuracy(predictions, batch.label)\n","\n","            loss.backward(retain_graph=True)\n","            val_loss+=compute_loss(model, val_iter,criterion)\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","    #         epoch_acc += acc.item()\n","        print(f'epoch {epoch+1} epoch_loss {epoch_loss/len(train_iterator)} val_loss {val_loss} ')\n","        metrics.append(epoch_loss)\n","    return epoch_loss / len(train_iterator), np.mean(val_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:06.617284Z","start_time":"2020-03-01T06:01:57.403076Z"},"id":"Kq8r3dku2LE4","colab_type":"code","colab":{}},"source":["# %debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:06.629578Z","start_time":"2020-03-01T06:02:06.620400Z"},"id":"3ssysuFM2LFC","colab_type":"code","outputId":"db01a1db-d94c-4637-eb93-0f2a9136feab","executionInfo":{"status":"ok","timestamp":1583314005369,"user_tz":-330,"elapsed":972,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["model"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GRUNet(\n","  (embedding): Embedding(8200, 1000, padding_idx=0)\n","  (gru): GRU(1000, 2000, num_layers=2, batch_first=True, dropout=0.2)\n","  (fc): Linear(in_features=2000, out_features=2806, bias=True)\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"8Hs1Bag52-YN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AOCHzltjwHj6","colab_type":"code","colab":{}},"source":["config ={\n","    \n","    \"embed_dim\" : model.embedding.embedding_dim,\n","    \"gru_hidden_size\":model.gru.hidden_size,\n","    \"gru_layers\":  model.gru.num_layers,\n","    \"avtivation\":'sigmoid',\n","        \n","}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYHLDKpKwHkC","colab_type":"code","outputId":"c49db394-88bb-40ef-d3b2-b4db7c3c1c35","executionInfo":{"status":"ok","timestamp":1583314013285,"user_tz":-330,"elapsed":1032,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","K = np.arange(100,201,10)\n","K"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200])"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"uu_Ph1ljwHkL","colab_type":"code","outputId":"79adcea4-cefe-49f2-c787-a286495cc981","executionInfo":{"status":"ok","timestamp":1583314035290,"user_tz":-330,"elapsed":6677,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!mkdir all/2\n","!mkdir medicines/4/"],"execution_count":44,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘all/2’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qUjOWY3nwHkT","colab_type":"code","colab":{}},"source":["# folder ='all/4/'\n","folder ='medicines/4/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Kqko5jTwHkb","colab_type":"code","colab":{}},"source":["import json, os\n","with open(os.path.join(folder,'config.json'), 'w') as fp:\n","    json.dump(config, fp, indent=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:36.972716Z","start_time":"2020-03-01T06:02:36.845449Z"},"scrolled":true,"id":"e0cXBv5KwHkj","colab_type":"code","outputId":"b37fedc2-712e-4426-ebb7-24f410284906","executionInfo":{"status":"error","timestamp":1583222288240,"user_tz":-330,"elapsed":3095,"user":{"displayName":"Sai Teja","photoUrl":"","userId":"03261428593993315926"}},"colab":{"base_uri":"https://localhost:8080/","height":839}},"source":["import os\n","from collections import defaultdict\n","from matplotlib import pyplot as plt    \n","\n","loses_list = ['train_loss','val_loss',]\n","recall_list = ['train_recall', 'test_recall']    \n","losses = defaultdict(list)    \n","recalls = defaultdict(lambda: defaultdict(list))\n","\n","for i in range(100):\n","    print('started_training')\n","    train_loss, val_loss = train(model=model, train_iterator=train_iter,\n","                                 optimizer=optimizer, criterion=criterion, val_iterator=val_iter, epochs=1)\n","    print('trained ', i)\n","    losses['train'].append(train_loss)\n","    losses['val'].append(val_loss)\n","    \n","    plt.style.use(\"ggplot\")\n","    plt.figure()\n","    N = np.arange(1,len(losses['train'])+1)\n","    plt.plot(N,losses['train'], label='Train_loss')\n","    plt.plot(N,losses['val'], label='Val_loss')\n","    plt.legend()\n","    plt.xlabel(\"Epoch #\")\n","    key ='loss'\n","    plt.ylabel(key)\n","    plt.title(f\"Training {key} {i}\")\n","    plt.savefig(os.path.join(folder,f'_{key}.png'))\n","    plt.close()  \n","\n","\n","\n","\n","    for k in K:\n","        recalls['train'][k].append(ham_loss(model=model,iterator=train_iter, k=k))\n","        recalls['test'][k].append(ham_loss(model=model,iterator=test_iter, k=k))\n","\n","        plt.plot()\n","        plt.style.use(\"ggplot\")\n","        plt.figure()\n","        N = np.arange(1,len(recalls['train'][k])+1)\n","        plt.plot(N,recalls['train'][k], label=f'Train_recall_{k}')\n","        plt.plot(N,recalls['test'][k], label=f'Test_recall_{k}')\n","        plt.legend()\n","        plt.xlabel(\"Epoch #\")\n","        key ='recall'\n","        plt.ylabel(key)\n","        plt.title(f\"Training {key} {i}\")\n","        plt.savefig(os.path.join(folder,f'_{key}_{k}.png'))\n","        plt.close()  \n","    \n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["started_training\n","epoch 1 epoch_loss 0.1680256108174453 val_loss 14.363899116061235 \n","trained  0\n","started_training\n","epoch 1 epoch_loss 0.11146084954207008 val_loss 10.557261847743858 \n","trained  1\n","started_training\n","epoch 1 epoch_loss 0.11267655060903446 val_loss 10.568049166547624 \n","trained  2\n","started_training\n","epoch 1 epoch_loss 0.11295321221287186 val_loss 10.618072965819588 \n","trained  3\n","started_training\n","epoch 1 epoch_loss 0.11453093779650894 val_loss 10.765679982931996 \n","trained  4\n","started_training\n","epoch 1 epoch_loss 0.11360115114901517 val_loss 10.649198083108976 \n","trained  5\n","started_training\n","epoch 1 epoch_loss 0.11473963409662247 val_loss 10.778784590332133 \n","trained  6\n","started_training\n","epoch 1 epoch_loss 0.11480067811302237 val_loss 10.768587931206351 \n","trained  7\n","started_training\n","epoch 1 epoch_loss 0.11608087019743146 val_loss 10.860725880453465 \n","trained  8\n","started_training\n","epoch 1 epoch_loss 0.11569054092507104 val_loss 10.857970436152662 \n","trained  9\n","started_training\n","epoch 1 epoch_loss 0.11773046065826674 val_loss 10.928959924335548 \n","trained  10\n","started_training\n","epoch 1 epoch_loss 0.11723661030063758 val_loss 10.939191980385464 \n","trained  11\n","started_training\n","epoch 1 epoch_loss 0.11731517848533553 val_loss 10.992599649648918 \n","trained  12\n","started_training\n","epoch 1 epoch_loss 0.11938362588753572 val_loss 11.052352919586392 \n","trained  13\n","started_training\n","epoch 1 epoch_loss 0.11965554902279699 val_loss 11.140315143293453 \n","trained  14\n","started_training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YMcPmdYKpZ2z","colab_type":"code","colab":{}},"source":["%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:36.972716Z","start_time":"2020-03-01T06:02:36.845449Z"},"id":"tchR5TyH2LFL","colab_type":"code","colab":{}},"source":["train_recall_125 = [ham_loss(model=model,iterator=train_iter, k=125)]\n","test_recall_125 = [ham_loss(model=model,iterator=test_iter, k=125)]\n","train_recall_100 = [ham_loss(model=model,iterator=train_iter, k=100)]\n","test_recall_100 = [ham_loss(model=model,iterator=test_iter,k=100)]\n","train_recall_150 = [ham_loss(model=model,iterator=train_iter, k=150)]\n","test_recall_150 = [ham_loss(model=model,iterator=test_iter,k=150)]\n","\n","for i in range(10):\n","    train(model=model, train_iterator=train_iter, optimizer=optimizer, criterion=criterion,\n","            val_iterator=val_iter, epochs=10)\n","    train_recall_125.append(ham_loss(model=model,iterator=train_iter, k=125))\n","    test_recall_125.append(ham_loss(model=model,iterator=test_iter, k=125))\n","    train_recall_100.append(ham_loss(model=model,iterator=train_iter, k=100))\n","    test_recall_100.append(ham_loss(model=model,iterator=test_iter, k=100))\n","    train_recall_150.append(ham_loss(model=model,iterator=train_iter, k=150))\n","    test_recall_150.append(ham_loss(model=model,iterator=test_iter, k=150))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLsEGfiV2LFS","colab_type":"code","colab":{}},"source":["test_recall_100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:09:50.788986Z","start_time":"2020-03-01T06:03:27.755529Z"},"id":"uGNLYNOJ2LFb","colab_type":"code","colab":{}},"source":["%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-16T05:14:36.630878Z","start_time":"2019-11-16T05:14:36.599348Z"},"id":"inrLNVzM2LFj","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), 'model3.pt')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-16T09:14:54.004905Z","start_time":"2019-11-16T09:14:53.947593Z"},"id":"Om3TRzlp2LFs","colab_type":"code","colab":{}},"source":["model.load_state_dict(torch.load('model3.pt'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T10:31:02.092246Z","start_time":"2019-11-13T10:30:58.186444Z"},"id":"plrsMjJq2LGD","colab_type":"code","colab":{}},"source":["val_loss=evaluate(model, val_iter,criterion)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T10:31:07.335210Z","start_time":"2019-11-13T10:31:07.329855Z"},"id":"xW8zcD5Q2LGL","colab_type":"code","colab":{}},"source":["val_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T08:37:36.469544Z","start_time":"2019-11-13T08:37:36.464199Z"},"id":"fPuLZ8dq2LGT","colab_type":"code","colab":{}},"source":["len(train_iter)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T05:28:48.412253Z","start_time":"2019-11-13T05:28:47.507Z"},"id":"v0b-GPlm2LGc","colab_type":"code","colab":{}},"source":["%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T05:28:48.412865Z","start_time":"2019-11-13T05:28:47.562Z"},"id":"ZyIZO3f82LGj","colab_type":"code","colab":{}},"source":["\n","class LSTMNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n","        super(LSTMNet, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","        \n","        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.relu = nn.ReLU()\n","        \n","    def forward(self, x, h):\n","        out, h = self.lstm(x, h)\n","        out = self.fc(self.relu(out[:,-1]))\n","        return out, h\n","    \n","    def init_hidden(self, batch_size):\n","        weight = next(self.parameters()).data\n","        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n","                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T05:17:09.166480Z","start_time":"2019-11-13T05:17:09.158065Z"},"id":"dM0HfN682LGu","colab_type":"code","colab":{}},"source":["def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=\"GRU\"):\n","    \n","    # Setting common hyperparameters\n","    input_dim = next(iter(train_loader))[0].shape[2]\n","    output_dim = input_dim\n","    n_layers = 1\n","    # Instantiating the models\n","    if model_type == \"GRU\":\n","        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n","    else:\n","        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n","    model.to(device)\n","    \n","    # Defining loss function and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n","    \n","    model.train()\n","    print(\"Starting Training of {} model\".format(model_type))\n","    epoch_times = []\n","    # Start training loop\n","    for epoch in range(1,EPOCHS+1):\n","        start_time = time.clock()\n","        h = model.init_hidden(batch_size)\n","        avg_loss = 0.\n","        counter = 0\n","        for x, label in train_loader:\n","            counter += 1\n","            if model_type == \"GRU\":\n","                h = h.data\n","            else:\n","                h = tuple([e.data for e in h])\n","            model.zero_grad()\n","            \n","            out, h = model(x.to(device).float(), h)\n","            loss = criterion(out, label.to(device).float())\n","            loss.backward()\n","            optimizer.step()\n","            avg_loss += loss.item()\n","            if counter%200 == 0:\n","                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n","        current_time = time.clock()\n","        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss/len(train_loader)))\n","        print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n","        epoch_times.append(current_time-start_time)\n","    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n","    return model\n","\n","def evaluate(model, test_x, test_y, label_scalers):\n","    model.eval()\n","    outputs = []\n","    targets = []\n","    start_time = time.clock()\n","    for i in test_x.keys():\n","        inp = torch.from_numpy(np.array(test_x[i]))\n","        labs = torch.from_numpy(np.array(test_y[i]))\n","        h = model.init_hidden(inp.shape[0])\n","        out, h = model(inp.to(device).float(), h)\n","        outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n","        targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n","    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n","    sMAPE = 0\n","    for i in range(len(outputs)):\n","        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n","    print(\"sMAPE: {}%\".format(sMAPE*100))\n","    return outputs, targets, sMAPE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T05:17:09.257167Z","start_time":"2019-11-13T05:17:09.227553Z"},"id":"dtxPinIY2LG5","colab_type":"code","colab":{}},"source":["new_array = np.array([1.2, 3.4, 5.6])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T15:33:37.253624Z","start_time":"2019-11-12T15:33:37.250752Z"},"id":"38rTORMy2LHK","colab_type":"code","colab":{}},"source":["train_ds[0].label.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:00:35.532459Z","start_time":"2020-03-01T07:00:35.529729Z"},"id":"I9IpSfzN2LHV","colab_type":"code","colab":{}},"source":["x = BucketIterator(train_ds, batch_size=4, sort_key='length')\n","# for y in x:\n","#     y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:01:30.902589Z","start_time":"2020-03-01T07:01:30.896798Z"},"id":"pyX21I882LHc","colab_type":"code","colab":{}},"source":["x.create_batches"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:55:56.564865Z","start_time":"2020-03-01T06:55:06.289292Z"},"id":"3C6xDGtV2LHk","colab_type":"code","colab":{}},"source":["%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:37:57.783512Z","start_time":"2020-03-01T07:37:57.652924Z"},"id":"zEY8LvUD2LHs","colab_type":"code","colab":{}},"source":["train_ds= DataFrameDataset(fields= fields, examples=train.iloc[:1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:37:58.724364Z","start_time":"2020-03-01T07:37:58.718163Z"},"id":"x1d-pL6z2LHy","colab_type":"code","colab":{}},"source":["y = BucketIterator(train_ds, batch_size=2,sort_key='length')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:37:59.618216Z","start_time":"2020-03-01T07:37:59.599209Z"},"id":"zZyMayr12LH8","colab_type":"code","colab":{}},"source":["for x in y:\n","    print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:44:32.007317Z","start_time":"2020-03-01T07:39:44.358986Z"},"scrolled":true,"id":"2Rf9zfSd2LIF","colab_type":"code","colab":{}},"source":["# train\n","%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2020-03-01T08:06:36.142Z"},"id":"oCTuJDEF2LIN","colab_type":"code","colab":{}},"source":["x =torch.randn((3,8199))\n","model(x,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylFkePgJ2LIV","colab_type":"code","colab":{}},"source":["10 epochs : 0.55(100) , 0.4(60)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EchBIgk2LIc","colab_type":"code","outputId":"8cb4c98a-69a6-4fd8-de31-36c83c52a08e","executionInfo":{"status":"error","timestamp":1583218502555,"user_tz":-330,"elapsed":3746,"user":{"displayName":"Sai Teja","photoUrl":"","userId":"03261428593993315926"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import os\n","from pathlib import Path\n","with open('../Gensim/tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)\n","wv_folder ='../Gensim/SG_data_2/word2vec/'\n","\n","files = os.listdir(wv_folder)\n","\n","\n","\n","import torch.optim as optim\n","\n","\n","\n","files = [x for x in filter(lambda x:x.split(\"_\")[0] == 'all', files)]\n","files  = [x for x in filter(lambda x:x.split(\"_\")[2] in ['500'] and x.split(\"_\")[3].split('.')[1] == 'wv', files)]\n","\n","file_paths = [ os.path.join(wv_folder, file) for file in files]\n","\n","K = np.arange(100,201,10)\n","\n","\n","\n","\n","\n","\n","import os\n","from collections import defaultdict\n","from matplotlib import pyplot as plt    \n","\n","\n","for file,file_path in zip(files,file_paths[0:]):\n","\n","  folder = Path((os.path.join(\"SG2\",(file).split('_')[0]+'/'+ (file).split('_')[3].split('.')[0]+'/'+file.split('_')[2])))\n","  folder.mkdir(parents=True,exist_ok=True)\n","  print(folder)\n","  print(f'file_path {file_path}')\n","  model = GRUNet(input_dim=100, hidden_dim=2000, output_dim=4386, n_layers=2, num_emd=8120, wv_file=file_path, tokenizer=tokenizer )\n","  model.init_weights(batch_size= BATCH_SIZE)\n","  model = model.to(device)\n","  optimizer = optim.Adam(model.parameters(), weight_decay=0.001)\n","\n","  criterion = nn.BCELoss(reduction='mean')\n","  \n","  \n","  criterion = criterion.to(device)\n","  \n","  # print(f'1 {device} {model.embedding.weight.device}')\n","  config ={\n","      \n","      \"embed_dim\" : model.embedding.embedding_dim,\n","      \"gru_hidden_size\":model.gru.hidden_size,\n","      \"gru_layers\":  model.gru.num_layers,\n","      \"avtivation\":'sigmoid',\n","      \"wv\": f'{file}',\n","          \n","  }\n","\n","  import json\n","  with open(os.path.join(folder, 'config.json'), 'w') as fp:\n","      json.dump(config, fp, indent=1)\n","\n","\n","  loses_list = ['train_loss','val_loss',]\n","  recall_list = ['train_recall', 'test_recall']    \n","  losses = defaultdict(list)    \n","  recalls = defaultdict(lambda: defaultdict(list))\n","\n","  for i in range(30):\n","      print('started_training')\n","      # print(f'2 {device} {model.embedding.weight.device}')\n","      train_loss, val_loss = train(model=model, train_iterator=train_iter,\n","                                  optimizer=optimizer, criterion=criterion, val_iterator=val_iter, epochs=1)\n","      print('trained ', i)\n","      losses['train'].append(train_loss)\n","      losses['val'].append(val_loss)\n","      \n","      plt.style.use(\"ggplot\")\n","      plt.figure()\n","      N = np.arange(1,len(losses['train'])+1)\n","      plt.plot(N,losses['train'], label='Train_loss')\n","      plt.plot(N,losses['val'], label='Val_loss')\n","      plt.legend()\n","      plt.xlabel(\"Epoch #\")\n","      key ='loss'\n","      plt.ylabel(key)\n","      plt.title(f\"Training {key} {i}\")\n","      plt.savefig(os.path.join(folder,f'_{key}.png'))\n","      plt.close()  \n","\n","\n","      \n","\n","      for k in K:\n","          recalls['train'][k].append(ham_loss(model=model,iterator=train_iter, k=k))\n","          recalls['test'][k].append(ham_loss(model=model,iterator=test_iter, k=k))\n","\n","          plt.plot()\n","          plt.style.use(\"ggplot\")\n","          plt.figure()\n","          N = np.arange(1,len(recalls['train'][k])+1)\n","          plt.plot(N,recalls['train'][k], label=f'Train_recall_{k}')\n","          plt.plot(N,recalls['test'][k], label=f'Test_recall_{k}')\n","          plt.legend()\n","          plt.xlabel(\"Epoch #\")\n","          key ='recall'\n","          plt.ylabel(key)\n","          plt.title(f\"Training {key} {i}\")\n","          plt.savefig(os.path.join(folder,f'{key}_{k}.png'))\n","          plt.close()  \n","      \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["SG2/all/5/500\n","all_data_500_5.wv\n","../Gensim/SG_data_2/word2vec/all_data_500_5.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["y  torch.Size([8199, 500])\n","started_training\n","epoch 1 epoch_loss 0.08422979041934013 val_loss 8.9911577174948\n","trained  0\n","started_training\n","epoch 1 epoch_loss 0.06326153764829916 val_loss 8.018481517210603\n","trained  1\n","started_training\n","epoch 1 epoch_loss 0.06450602973208708 val_loss 8.117772364650259\n","trained  2\n","started_training\n","epoch 1 epoch_loss 0.06598878818399766 val_loss 8.247509508647699\n","trained  3\n","started_training\n","epoch 1 epoch_loss 0.06730359897894019 val_loss 8.33284658515318\n","trained  4\n","started_training\n","epoch 1 epoch_loss 0.06790340700570274 val_loss 8.363020767542446\n","trained  5\n","started_training\n","epoch 1 epoch_loss 0.06896878660601728 val_loss 8.468369912017476\n","trained  6\n","started_training\n","epoch 1 epoch_loss 0.06924150739522542 val_loss 8.471003014763648\n","trained  7\n","started_training\n","epoch 1 epoch_loss 0.07084793102215318 val_loss 8.664397790858693\n","trained  8\n","started_training\n","epoch 1 epoch_loss 0.07004529921447529 val_loss 8.524045661091805\n","trained  9\n","started_training\n","epoch 1 epoch_loss 0.07066077572457931 val_loss 8.591488784348423\n","trained  10\n","started_training\n","epoch 1 epoch_loss 0.07038364905644866 val_loss 8.570525097237393\n","trained  11\n","started_training\n","epoch 1 epoch_loss 0.07076890626374413 val_loss 8.587901398200879\n","trained  12\n","started_training\n","epoch 1 epoch_loss 0.07048665745293393 val_loss 8.687151257118044\n","trained  13\n","started_training\n","epoch 1 epoch_loss 0.07118939612718189 val_loss 8.681739995086737\n","trained  14\n","started_training\n","epoch 1 epoch_loss 0.07097319338251562 val_loss 8.592346976087855\n","trained  15\n","started_training\n","epoch 1 epoch_loss 0.07088155373930931 val_loss 8.616055634888733\n","trained  16\n","started_training\n","epoch 1 epoch_loss 0.07110707295291564 val_loss 8.622466958212584\n","trained  17\n","started_training\n","epoch 1 epoch_loss 0.07157075391972766 val_loss 8.665184770964762\n","trained  18\n","started_training\n","epoch 1 epoch_loss 0.07136679190923186 val_loss 8.637720535593955\n","trained  19\n","started_training\n","epoch 1 epoch_loss 0.07150968979386722 val_loss 8.64728284102272\n","trained  20\n","started_training\n","epoch 1 epoch_loss 0.07135744011577438 val_loss 8.661074488169763\n","trained  21\n","started_training\n","epoch 1 epoch_loss 0.07122234978220042 val_loss 8.607895380563354\n","trained  22\n","started_training\n","epoch 1 epoch_loss 0.07113732743789168 val_loss 8.61533676663583\n","trained  23\n","started_training\n","epoch 1 epoch_loss 0.07099369689822196 val_loss 8.626654573462226\n","trained  24\n","started_training\n","epoch 1 epoch_loss 0.07163788614904179 val_loss 8.654828652231533\n","trained  25\n","started_training\n","epoch 1 epoch_loss 0.07128232498379315 val_loss 8.65630235472186\n","trained  26\n","started_training\n","epoch 1 epoch_loss 0.07154176804949255 val_loss 8.664908236061988\n","trained  27\n","started_training\n","epoch 1 epoch_loss 0.07079896400956547 val_loss 8.62468881515617\n","trained  28\n","started_training\n","epoch 1 epoch_loss 0.07142683850491748 val_loss 8.601412760601804\n","trained  29\n","SG2/all/10/500\n","all_data_500_10.wv\n","../Gensim/SG_data_2/word2vec/all_data_500_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["y  torch.Size([8199, 500])\n","started_training\n","epoch 1 epoch_loss 0.08253124579787255 val_loss 8.832640887153413\n","trained  0\n","started_training\n","epoch 1 epoch_loss 0.06296422043267419 val_loss 7.975540513680741\n","trained  1\n","started_training\n","epoch 1 epoch_loss 0.064579789384323 val_loss 8.106155736371877\n","trained  2\n","started_training\n","epoch 1 epoch_loss 0.06558058283784811 val_loss 8.188554568216205\n","trained  3\n","started_training\n","epoch 1 epoch_loss 0.06704350398743854 val_loss 8.317197033119468\n","trained  4\n","started_training\n","epoch 1 epoch_loss 0.0671622168053599 val_loss 8.320239981297743\n","trained  5\n","started_training\n","epoch 1 epoch_loss 0.06905111512717078 val_loss 8.458048848604612\n","trained  6\n","started_training\n","epoch 1 epoch_loss 0.06919546583119561 val_loss 8.501973955130037\n","trained  7\n","started_training\n","epoch 1 epoch_loss 0.06962373655508547 val_loss 8.490980000150476\n","trained  8\n","started_training\n","epoch 1 epoch_loss 0.06959048566572806 val_loss 8.501488050276583\n","trained  9\n","started_training\n","epoch 1 epoch_loss 0.06972527153351728 val_loss 8.536908141422002\n","trained  10\n","started_training\n","epoch 1 epoch_loss 0.07086354143479291 val_loss 8.61418220756406\n","trained  11\n","started_training\n","epoch 1 epoch_loss 0.07110666290802115 val_loss 8.632006990299978\n","trained  12\n","started_training\n","epoch 1 epoch_loss 0.07010534602929563 val_loss 8.586046315560289\n","trained  13\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d8Pk9YbTEsFo","colab_type":"code","colab":{}},"source":["pwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M44stVezEv98","colab_type":"code","outputId":"a55c1c82-cf4d-470e-cef1-f3cbddfe3356","executionInfo":{"status":"ok","timestamp":1583218967712,"user_tz":-330,"elapsed":1086,"user":{"displayName":"Sai Teja","photoUrl":"","userId":"03261428593993315926"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["model.embedding.weight.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5394, 100])"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"WA8rfqCSLaas","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}