{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"Dr_AI_medicines.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NFRD7HcxwSEG","colab_type":"code","outputId":"c60235d5-52c5-49b9-f450-171d76803c68","executionInfo":{"status":"ok","timestamp":1583319727902,"user_tz":-330,"elapsed":6307,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["!pip install --upgrade tables"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: tables in /usr/local/lib/python3.6/dist-packages (3.6.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.17.5)\n","Requirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DOpikSXbsvn-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"9cfdeea4-5cce-471d-9d86-5c7ad22561f5","executionInfo":{"status":"ok","timestamp":1583319735398,"user_tz":-330,"elapsed":11984,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}}},"source":["\n","\n","\n","# Upload the train file from your local drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UgRbzJw_zGWK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8ac94b95-58d9-413d-e244-b6bf917860b0","executionInfo":{"status":"ok","timestamp":1583319735400,"user_tz":-330,"elapsed":9831,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}}},"source":["cd /content/drive/My\\ Drive/Dr_AI"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Dr_AI\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kfJh856KaUso","colab_type":"code","colab":{}},"source":["!ls ../word2vec-pytorch-master/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDlacPxFwSAU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oi1-lusJwR4f","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.113315Z","start_time":"2020-03-01T08:07:17.375425Z"},"id":"tCcNNwTFwHdM","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import torch \n","from torch import nn\n","from collections import defaultdict\n","\n","\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchtext.data import Field, Dataset, Example\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score,hamming_loss\n","\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.122761Z","start_time":"2020-03-01T08:07:18.114589Z"},"id":"UEoTYwXSwHds","colab_type":"code","colab":{}},"source":["# loading\n","with open('tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.310131Z","start_time":"2020-03-01T08:07:18.124438Z"},"id":"XQ0A97F4wHeG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f36cb37a-4492-4407-ab9e-4d745c1f6bea","executionInfo":{"status":"ok","timestamp":1583319743356,"user_tz":-330,"elapsed":1266,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}}},"source":["tokenizer.sequences_to_texts([[1,2,3]])"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['potassium_chloride insulin furosemide']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.513597Z","start_time":"2020-03-01T08:07:18.311382Z"},"id":"kCr4YbVOwHec","colab_type":"code","colab":{}},"source":["\n","class DataFrameDataset(Dataset):\n"," \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n","#  def __init__(self, fields, path='./test1.h5', filter_pred=None):\n"," def __init__(self, fields, examples, filter_pred=None): \n","    \"\"\"\n","     Create a dataset from a pandas dataframe of examples and Fields\n","     Arguments:\n","         examples pd.DataFrame: DataFrame of examples\n","         fields {str: Field}: The Fields to use in this tuple. The\n","             string is a field name, and the Field is the associated field.\n","         filter_pred (callable or None): use only exanples for which\n","             filter_pred(example) is true, or use all examples if None.\n","             Default is None\n","    \"\"\"\n","#     examples = pd.read_hdf(path)\n","    self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n","    if filter_pred is not None:\n","         self.examples = filter(filter_pred, self.examples)\n","    self.fields = dict(fields)\n","     # Unpack field tuples\n","    for n, f in list(self.fields.items()):\n","         if isinstance(n, tuple):\n","            self.fields.update(zip(n, f))\n","            del self.fields[n]\n","\n","class SeriesExample(Example):\n","    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n","\n","    @classmethod \n","    def fromSeries(cls, data, fields):\n","        return cls.fromdict(data.to_dict(), fields)\n","\n","    @classmethod\n","    def fromdict(cls, data, fields):\n","        ex = cls()\n","        fields = dict(fields)\n","#         print(fields.items())\n","        for key, field in fields.items():\n","#             print(key)\n","            if key not in data:\n","                 raise ValueError(\"Specified key {} was not found in \"\n","         \"the input data\".format(key))\n","            if field is not None:\n","                setattr(ex, key, field.preprocess(data[key]))\n","#                 print(field.preprocess(data[key]))   \n","            else:\n","                 setattr(ex, key, data[key])\n","#         print(ex.input.pad_)        \n","        return ex"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.691871Z","start_time":"2020-03-01T08:07:18.514827Z"},"id":"OE54StoewHet","colab_type":"code","colab":{}},"source":["LABEL = Field(sequential=True,use_vocab=False,batch_first=True,pad_token=[0]*2806)\n","INPUT = Field(sequential=True,use_vocab=False,batch_first=True,pad_token=[0]*1343)\n","LENGTH = Field(sequential=False,use_vocab=False,batch_first=True,pad_token=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:18.933803Z","start_time":"2020-03-01T08:07:18.693071Z"},"id":"OoOqHVr3wHe-","colab_type":"code","colab":{}},"source":["fields = [('label',LABEL),('input',INPUT),('length',LENGTH)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:22.834239Z","start_time":"2020-03-01T08:07:18.935547Z"},"id":"O9mNpNdwwHfM","colab_type":"code","colab":{}},"source":["final_df2 = pd.read_hdf('./m_test.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:22.839056Z","start_time":"2020-03-01T08:07:22.835589Z"},"id":"gmowhW9jwHfY","colab_type":"code","colab":{}},"source":["final_df2.columns\n","final_df2 = final_df2.rename({'labels':'label', 'lengths':'length'},axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:23.367072Z","start_time":"2020-03-01T08:07:22.840536Z"},"id":"w7Xq1AhlwHfo","colab_type":"code","colab":{}},"source":["train_set, test = train_test_split(final_df2, test_size=0.1)\n","train_set, val = train_test_split(train_set, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:28.389256Z","start_time":"2020-03-01T08:07:23.368277Z"},"id":"S7q1crOiwHf1","colab_type":"code","colab":{}},"source":["train_ds = DataFrameDataset(fields, train_set)\n","val_ds = DataFrameDataset(fields, val)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:28.890064Z","start_time":"2020-03-01T08:07:28.390696Z"},"id":"FuZKB73hwHgE","colab_type":"code","colab":{}},"source":["test_ds = DataFrameDataset(fields=fields, examples=test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:28.893843Z","start_time":"2020-03-01T08:07:28.891496Z"},"id":"HMV3h3QbwHgU","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","\n","\n"," \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjS2FnDAwHgg","colab_type":"code","colab":{}},"source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKaD_ZkrwHgs","colab_type":"code","colab":{}},"source":["# device = torch.device(\"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:29.008103Z","start_time":"2020-03-01T08:07:28.895094Z"},"id":"CFZ7boIQwHg8","colab_type":"code","colab":{}},"source":["from torchtext.data import Iterator, BucketIterator\n","\n","train_iter, val_iter, test_iter = BucketIterator.splits(\n"," (train_ds,val_ds,test_ds), # we pass in the datasets we want the iterator to draw data from\n"," batch_sizes=(BATCH_SIZE, BATCH_SIZE,BATCH_SIZE),\n"," device=device, # if you want to use the GPU, specify the GPU number here\n"," sort_key=lambda x: x.length, # the BucketIterator needs to be told what function it should use to group the data.\n"," sort_within_batch=True,\n"," repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",")\n","# test_iter = Iterator(tst, batch_size=64, device=-1, sort=False, sort_within_batch=False, repeat=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sra-D6pEwHhG","colab_type":"code","colab":{}},"source":["# for batch in train_iter:\n","#     print(f'{batch.input[0]}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:07:29.137863Z","start_time":"2020-03-01T08:07:29.009389Z"},"id":"nv0gf_XhwHhR","colab_type":"code","colab":{}},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:08:15.418062Z","start_time":"2020-03-01T08:08:15.408738Z"},"id":"DbDdL-HhwHhc","colab_type":"code","colab":{}},"source":["class GRUNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, num_emd, drop_prob=0.2, wv_file=None, tokenizer=None ):\n","        super(GRUNet, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","        self.drop_prob = drop_prob\n","\n","        self.embedding = nn.Embedding(embedding_dim=input_dim, num_embeddings=num_emd, padding_idx=0)\n","        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.sigmoid = nn.Sigmoid()\n","        self.wv_file =  wv_file\n","        self.tokenizer = tokenizer\n","        \n","    def forward(self, x,length):\n","        out = self.embedding(x)\n","#         print(f'before sum {out.shape}')\n","\n","        out = out.sum(dim=-2)\n","        # print(f'before packing {out.shape} ')\n","        out = torch.nn.utils.rnn.pack_padded_sequence(out, lengths=length, batch_first=True, enforce_sorted=True)\n","        # print(f'after packing {out.data.shape}  {out.batch_sizes} {length} {out}')\n","           \n","        packed_output, h = self.gru(out)\n","        out, out_lengths = torch.nn.utils.rnn.pad_packed_sequence(packed_output)\n","#         print(f'after unpacking {out.shape} {out_lengths.shape}')\n","        out = out.transpose(0,1)\n","        out = self.fc(out)\n","\n","        out=self.sigmoid(out)\n","        return out, h\n","    \n","    def init_weights( self, batch_size):\n","        \n","      if self.wv_file:\n","          print(self.wv_file)\n","          from gensim.models import KeyedVectors, Word2Vec\n","\n","          wv = KeyedVectors.load(self.wv_file)\n","          word_indexer  = self.tokenizer.word_index\n","          \n","          wv_2 = {}\n","\n","          for word in word_indexer:\n","              try:\n","                  wv_2[word_indexer[word]]= wv[word]\n","              except KeyError as k:\n","                  wv_2[word_indexer[word]] = np.zeros(wv.vector_size)\n","\n","          wv_2\n","          x = [v for k, v in sorted(wv_2.items(), key=lambda item: item[0], reverse=False)]\n","\n","          pad = np.zeros_like(x[0])\n","          x.insert(0,pad)\n","          y = torch.tensor(x, dtype=torch.float32)\n","          \n","          device = self.embedding.weight.device\n","          self.embedding.weight =  torch.nn.Parameter(y)\n","          self.embedding = self.embedding.to(device)\n","          self.gru = nn.GRU(wv.vector_size, self.hidden_dim, self.n_layers, batch_first=True, dropout=self.drop_prob).to(device)\n","\n","      self.init_hidden(batch_size)\n","\n","          \n","    def init_hidden(self, batch_size ):\n","        weight = next(self.parameters()).data\n","        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:55.879342Z","start_time":"2020-03-01T06:01:55.874584Z"},"id":"lqLLZnW9wHhl","colab_type":"code","colab":{}},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:56.109494Z","start_time":"2020-03-01T06:01:56.106412Z"},"id":"tqbYdY-OwHhy","colab_type":"code","colab":{}},"source":["def compute_loss(model, iterator, criterion):\n","    loss = 0\n","    for batch in iterator:\n","        text = batch.input\n","        text_lengths = batch.length\n","\n","        predictions,h = model(text, text_lengths)\n","#         print(f'predictions.shape {predictions}')\n","#         print(f'\\n\\n labels \\n{batch.label.dtype} \\n\\n predictions\\n {predictions.dtype}')\n","        label = batch.label.to(dtype=torch.float32)\n","        loss += criterion(predictions, label).item()\n","    return loss/len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:56.316722Z","start_time":"2020-03-01T06:01:56.314915Z"},"id":"4ndOm_vCwHh8","colab_type":"code","colab":{}},"source":["k = 30"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:56.530840Z","start_time":"2020-03-01T06:01:56.524307Z"},"id":"DoMGDKIPwHiH","colab_type":"code","colab":{}},"source":["def ham_loss(model, iterator, k=60):\n","    acc = 0\n","    n_samples = 0\n","    recall = []\n","    \n","    for batch in iterator:\n","        text = batch.input\n","        text_lengths = batch.length\n","\n","        predictions,h = model(text, text_lengths)\n","        predictions = (predictions.detach().cpu().numpy()).reshape(predictions.shape[0]*predictions.shape[1],-1)\n","        labels = np.array(batch.label.cpu()).reshape(batch.label.shape[0]*batch.label.shape[1],-1)\n","        \n","#         pred_seq = [np.where(x[0]==1)[0] for x in predictions]\n","        label_seq = [np.where(x==1)[0] for x in labels]\n","#         predictions = predictions.reshape(predictions.shape[0]*predictions.shape[1],-1)\n","        try :    \n","            for p,q in zip(label_seq,predictions):\n","                pred =np.sort(np.argsort(q)[-k:])\n","                acc += (np.intersect1d(pred,p)).size\n","                n_samples+=(p.size)   \n","                rec = (np.intersect1d(pred,p)).size/p.size\n","                recall.append(rec)\n","    #             print(acc)\n","    #             print(n_samples, len(p))\n","    #         acc += np.sum(np.not_equal(pred_seq, label_seq))\n","        except ZeroDivisionError as z:\n","            continue\n","        \n","    return(np.mean(recall))       "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:33.271536Z","start_time":"2020-03-01T06:02:33.260383Z"},"id":"_EbZ81DjwHiT","colab_type":"code","colab":{}},"source":["\n","def train(model, train_iterator, optimizer, criterion, val_iterator,epochs=100):\n","    \n","    metrics = []\n","    epoch_loss = 0\n","    val_loss = 0\n","    \n","    model.train()\n","    h = model.init_weights(batch_size=BATCH_SIZE)\n","\n","    for epoch in range(epochs):  \n","        epoch_loss = 0\n","        for batch in train_iterator:\n","\n","            optimizer.zero_grad()\n","\n","            text = batch.input\n","            text_lengths = batch.length\n","            # print(text)\n","            predictions,h = model(text, text_lengths)\n","            # print(f'predictions.shape {predictions}')\n","    #         print(f'\\n\\n labels \\n{batch.label.dtype} \\n\\n predictions\\n {predictions.dtype}')\n","            label = batch.label.to(dtype=torch.float32)\n","            # print(f'{predictions.shape} {label.shape}')\n","            loss = criterion(predictions, label)\n","    #         acc = binary_accuracy(predictions, batch.label)\n","\n","            loss.backward(retain_graph=True)\n","            val_loss+=compute_loss(model, val_iter,criterion)\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","    #         epoch_acc += acc.item()\n","        print(f'epoch {epoch+1} epoch_loss {epoch_loss/len(train_iterator)} val_loss {val_loss} ')\n","        metrics.append(epoch_loss)\n","    return epoch_loss / len(train_iterator), np.mean(val_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T08:06:32.682179Z","start_time":"2020-03-01T08:06:32.462360Z"},"scrolled":true,"id":"4jZroDu-wHid","colab_type":"code","colab":{}},"source":["import os\n","with open('../Gensim/d_tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)\n","wv_folder ='../Gensim/SG_data/word2vec/'\n","\n","files = os.listdir(wv_folder)\n","file_paths = [ os.path.join(wv_folder, file) for file in files]\n","\n","\n","model = GRUNet(input_dim=1000, hidden_dim=2000, output_dim=2806, n_layers=2, num_emd=8200)# wv_file=os.path.join(wv_folder, files[0]), tokenizer=tokenizer )\n","# model.init_weights(batch_size= BATCH_SIZE)\n","\n","\n","# # model = GRUNet(input_dim=1000, hidden_dim=200, output_dim=1581, n_layers=2, num_emd=5395)\n","model = model.to(device)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"36csENyYePFN","colab_type":"code","colab":{}},"source":["# model.gru.all_weights\n","# model.embedding.weight\n","# model.embedding.num_embeddings, model.embedding.weight.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:57.255966Z","start_time":"2020-03-01T06:01:56.948065Z"},"id":"kVNtGRq5wHio","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"ba816227-86e6-4112-d38a-f18d0d46f36a","executionInfo":{"status":"ok","timestamp":1583319952506,"user_tz":-330,"elapsed":8457,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}}},"source":["print(f'train {ham_loss(model=model,iterator=train_iter)} \\n\\n val {ham_loss(model=model,iterator=val_iter)}')\n","ham_loss(model=model,iterator=test_iter, k=100)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["train 0.021159152271721236 \n","\n"," val 0.02115178368749996\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.03654228096880196"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"0RtrE80vwHix","colab_type":"code","colab":{}},"source":["# %debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:55.233905Z","start_time":"2020-03-01T06:01:55.229523Z"},"id":"zGPX9acHwHi7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"c7048b59-a264-4379-b3f9-67c50e5d4acf","executionInfo":{"status":"ok","timestamp":1583319956467,"user_tz":-330,"elapsed":943,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["The model has 55,838,806 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:55.460640Z","start_time":"2020-03-01T06:01:55.458502Z"},"id":"o_wWXlbtwHjF","colab_type":"code","outputId":"05cfa71c-20f4-4675-fc43-eab0c0363be3","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1583317599707,"user_tz":-330,"elapsed":4432889,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}}},"source":["import os\n","from pathlib import Path\n","with open('../Gensim/m_tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)\n","wv_folder ='../Gensim/SG_data3/word2vec/'\n","\n","files = os.listdir(wv_folder)\n","\n","files = [x for x in filter(lambda x:x.split(\"_\")[0] == 'medicines', files)]\n","\n","\n","import torch.optim as optim\n","\n","\n","\n","files = [x for x in filter(lambda x:x.split(\"_\")[2] in ['1000'] and x.split(\"_\")[3].split('.')[1] == 'wv', files)]\n","file_paths = [ os.path.join(wv_folder, file) for file in files]\n","print(file_paths[0])\n","K = np.arange(10,101,10)\n","\n","\n","\n","import os\n","from collections import defaultdict\n","from matplotlib import pyplot as plt    \n","\n","\n","for file,file_path in zip(files,file_paths[0:]):\n","\n","  folder = Path((os.path.join(\"SG2\",(file).split('_')[0]+'/'+ (file).split('_')[3].split('.')[0]+'/'+file.split('_')[2])))\n","  folder.mkdir(parents=True,exist_ok=True)\n","  print(folder)\n","  print(f'file_path {file_path}')\n","  model = GRUNet(input_dim=100, hidden_dim=200, output_dim=2806, n_layers=2, num_emd=8200, wv_file=file_path, tokenizer=tokenizer )\n","  model.init_weights(batch_size= BATCH_SIZE)\n","  model = model.to(device)\n","  optimizer = optim.Adam(model.parameters(), weight_decay=0.001)\n","\n","  criterion = nn.BCELoss(reduction='mean')\n","  \n","  \n","  criterion = criterion.to(device)\n","  \n","  # print(f'1 {device} {model.embedding.weight.device}')\n","  config ={\n","      \n","      \"embed_dim\" : model.embedding.embedding_dim,\n","      \"gru_hidden_size\":model.gru.hidden_size,\n","      \"gru_layers\":  model.gru.num_layers,\n","      \"avtivation\":'sigmoid',\n","      \"wv\": f'{file}',\n","          \n","  }\n","\n","  loses_list = ['train_loss','val_loss',]\n","  recall_list = ['train_recall', 'test_recall']    \n","  losses = defaultdict(list)    \n","  recalls = defaultdict(lambda: defaultdict(list))\n","\n","  for i in range(30):\n","      print('started_training')\n","      # print(f'2 {device} {model.embedding.weight.device}')\n","      train_loss, val_loss = train(model=model, train_iterator=train_iter,\n","                                  optimizer=optimizer, criterion=criterion, val_iterator=val_iter, epochs=1)\n","      print('trained ', i)\n","      losses['train'].append(train_loss)\n","      losses['val'].append(val_loss)\n","      \n","      plt.style.use(\"ggplot\")\n","      plt.figure()\n","      N = np.arange(1,len(losses['train'])+1)\n","      plt.plot(N,losses['train'], label='Train_loss')\n","      plt.plot(N,losses['val'], label='Val_loss')\n","      plt.legend()\n","      plt.xlabel(\"Epoch #\")\n","      key ='loss'\n","      plt.ylabel(key)\n","      plt.title(f\"Training {key} {i}\")\n","      plt.savefig(os.path.join(folder,f'_{key}.png'))\n","      plt.close()  \n","\n","\n","      \n","\n","      for k in K:\n","          recalls['train'][k].append(ham_loss(model=model,iterator=train_iter, k=k))\n","          recalls['test'][k].append(ham_loss(model=model,iterator=test_iter, k=k))\n","\n","          plt.plot()\n","          plt.style.use(\"ggplot\")\n","          plt.figure()\n","          N = np.arange(1,len(recalls['train'][k])+1)\n","          plt.plot(N,recalls['train'][k], label=f'Train_recall_{k}')\n","          plt.plot(N,recalls['test'][k], label=f'Test_recall_{k}')\n","          plt.legend()\n","          plt.xlabel(\"Epoch #\")\n","          key ='recall'\n","          plt.ylabel(key)\n","          plt.title(f\"Training {key} {i}\")\n","          plt.savefig(os.path.join(folder,f'{key}_{k}.png'))\n","          plt.close()  \n","      \n","      "],"execution_count":32,"outputs":[{"output_type":"stream","text":["../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n","SG2/medicines/10/1000\n","file_path ../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n","epoch 1 epoch_loss 0.5788659811825365 val_loss 43.28509059548378 \n","trained  0\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.5366543019945557 val_loss 40.388065680077204 \n","trained  1\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.5097833968497612 val_loss 38.4814636566137 \n","trained  2\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.4927650375946148 val_loss 37.31628598978645 \n","trained  3\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.517696453510104 val_loss 38.8670885500155 \n","trained  4\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.491634362452739 val_loss 37.073652789780965 \n","trained  5\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.49558982857175776 val_loss 37.3337284059901 \n","trained  6\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.4795090113137219 val_loss 36.27128540371594 \n","trained  7\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.485291278442821 val_loss 36.63724038946003 \n","trained  8\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.513290449574187 val_loss 38.47953852070005 \n","trained  9\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.48421667596778356 val_loss 36.55040629286516 \n","trained  10\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.4962030278669821 val_loss 37.40172069794253 \n","trained  11\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.49754055972034866 val_loss 37.577373920302634 \n","trained  12\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.496718728059047 val_loss 37.39581965302167 \n","trained  13\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.49776759864510717 val_loss 37.44089918858127 \n","trained  14\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.512545099532282 val_loss 38.557213910316165 \n","trained  15\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.4833157014202427 val_loss 36.55540994280263 \n","trained  16\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.5133509946030539 val_loss 38.42090409209853 \n","trained  17\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.48587517319498835 val_loss 36.769872922646385 \n","trained  18\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.49410025211604863 val_loss 37.115977105341464 \n","trained  19\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.5014025500497302 val_loss 37.63435545249989 \n","trained  20\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.4947914887924452 val_loss 37.33290339614217 \n","trained  21\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.4977079521159868 val_loss 37.490681445912294 \n","trained  22\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.5001556333657857 val_loss 37.62786261972629 \n","trained  23\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.5027008978901683 val_loss 37.93063226812764 \n","trained  24\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.4916131798480008 val_loss 37.041232411798674 \n","trained  25\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.48244777482909124 val_loss 36.46167805163485 \n","trained  26\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.48965167515986674 val_loss 37.016473781121405 \n","trained  27\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.5121815361686655 val_loss 38.52284656072918 \n","trained  28\n","started_training\n","../Gensim/SG_data3/word2vec/medicines_data_1000_10.wv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1 epoch_loss 0.4888231383787619 val_loss 36.81194897701865 \n","trained  29\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAEQCAYAAACz0c/rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:01:55.669349Z","start_time":"2020-03-01T06:01:55.666150Z"},"id":"zmZywZoGwHjN","colab_type":"code","colab":{}},"source":["%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvTIBoBxwHjY","colab_type":"code","colab":{}},"source":["model.gru.all_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:06.617284Z","start_time":"2020-03-01T06:01:57.403076Z"},"id":"Wh7EFSBXwHjg","colab_type":"code","colab":{}},"source":["# %debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:06.629578Z","start_time":"2020-03-01T06:02:06.620400Z"},"id":"xy05fJWfwHjo","colab_type":"code","colab":{}},"source":["model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tY5CUowUwHjy","colab_type":"code","colab":{}},"source":["x = model.gru.num_layers\n","x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AOCHzltjwHj6","colab_type":"code","colab":{}},"source":["\n","config ={\n","      \n","      \"embed_dim\" : model.embedding.embedding_dim,\n","      \"gru_hidden_size\":model.gru.hidden_size,\n","      \"gru_layers\":  model.gru.num_layers,\n","      \"avtivation\":'sigmoid',\n","      # \"wv\": f'{file}',\n","          \n","  }\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYHLDKpKwHkC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"3175bd2f-904b-4769-9982-be914126a551","executionInfo":{"status":"ok","timestamp":1583320021795,"user_tz":-330,"elapsed":993,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}}},"source":["import numpy as np\n","K = np.arange(90,151,10)\n","K"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 90, 100, 110, 120, 130, 140, 150])"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"uu_Ph1ljwHkL","colab_type":"code","colab":{}},"source":["!mkdir medicnes/4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qUjOWY3nwHkT","colab_type":"code","colab":{}},"source":["# folder ='diagnosis//'\n","folder ='medicines/4'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Kqko5jTwHkb","colab_type":"code","colab":{}},"source":["import json,os\n","with open(os.path.join(folder,'config.json'), 'w') as fp:\n","    json.dump(config, fp, indent=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:02:36.972716Z","start_time":"2020-03-01T06:02:36.845449Z"},"scrolled":true,"id":"e0cXBv5KwHkj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c58a7091-0d3d-40fc-f671-175848556e88","executionInfo":{"status":"ok","timestamp":1583332200572,"user_tz":-330,"elapsed":12062962,"user":{"displayName":"Gautham dasu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuEaJpPLUrRy0rGHCume8QnQs-cch-NejSweo=s64","userId":"10626183786997085147"}}},"source":["import os\n","from collections import defaultdict\n","from matplotlib import pyplot as plt\n","import torch.optim as optim\n","optimizer = optim.Adam(model.parameters(), weight_decay=0.001)\n","\n","criterion = nn.BCELoss(reduction='mean')\n","\n","\n","criterion = criterion.to(device)\n","\n","\n","loses_list = ['train_loss','val_loss',]\n","recall_list = ['train_recall', 'test_recall']    \n","losses = defaultdict(list)    \n","recalls = defaultdict(lambda: defaultdict(list))\n","\n","for i in range(100):\n","    print('started_training')\n","    train_loss, val_loss = train(model=model, train_iterator=train_iter,\n","                                 optimizer=optimizer, criterion=criterion, val_iterator=val_iter, epochs=1)\n","    print('trained ', i)\n","    losses['train'].append(train_loss)\n","    losses['val'].append(val_loss)\n","    \n","    plt.style.use(\"ggplot\")\n","    plt.figure()\n","    N = np.arange(1,len(losses['train'])+1)\n","    plt.plot(N,losses['train'], label='Train_loss')\n","    plt.plot(N,losses['val'], label='Val_loss')\n","    plt.legend()\n","    plt.xlabel(\"Epoch #\")\n","    key ='loss'\n","    plt.ylabel(key)\n","    plt.title(f\"Training {key} {i}\")\n","    plt.savefig(os.path.join(folder,f'_{key}.png'))\n","    plt.close()  \n","\n","\n","\n","\n","    for k in K:\n","        recalls['train'][k].append(ham_loss(model=model,iterator=train_iter, k=k))\n","        recalls['test'][k].append(ham_loss(model=model,iterator=test_iter, k=k))\n","\n","        plt.plot()\n","        plt.style.use(\"ggplot\")\n","        plt.figure()\n","        N = np.arange(1,len(recalls['train'][k])+1)\n","        plt.plot(N,recalls['train'][k], label=f'Train_recall_{k}')\n","        plt.plot(N,recalls['test'][k], label=f'Test_recall_{k}')\n","        plt.legend()\n","        plt.xlabel(\"Epoch #\")\n","        key ='recall'\n","        plt.ylabel(key)\n","        plt.title(f\"Training {key} {i}\")\n","        plt.savefig(os.path.join(folder,f'_{key}_{k}.png'))\n","        plt.close()  \n","    \n","    "],"execution_count":41,"outputs":[{"output_type":"stream","text":["started_training\n","epoch 1 epoch_loss 0.08398577988751836 val_loss 9.030361024564817 \n","trained  0\n","started_training\n","epoch 1 epoch_loss 0.06128123845603015 val_loss 7.488814656867795 \n","trained  1\n","started_training\n","epoch 1 epoch_loss 0.06141196100695713 val_loss 7.509198909527376 \n","trained  2\n","started_training\n","epoch 1 epoch_loss 0.061317266443291225 val_loss 7.506194893074662 \n","trained  3\n","started_training\n","epoch 1 epoch_loss 0.06130609102547169 val_loss 7.481792454460733 \n","trained  4\n","started_training\n","epoch 1 epoch_loss 0.06191745400428772 val_loss 7.522732537631925 \n","trained  5\n","started_training\n","epoch 1 epoch_loss 0.06148648659723836 val_loss 7.492417648826776 \n","trained  6\n","started_training\n","epoch 1 epoch_loss 0.0618868820067193 val_loss 7.522620050530686 \n","trained  7\n","started_training\n","epoch 1 epoch_loss 0.061637846904026496 val_loss 7.507682939893322 \n","trained  8\n","started_training\n","epoch 1 epoch_loss 0.06170028634369373 val_loss 7.517504093286238 \n","trained  9\n","started_training\n","epoch 1 epoch_loss 0.062121361242355524 val_loss 7.548302514968735 \n","trained  10\n","started_training\n","epoch 1 epoch_loss 0.06163796435135442 val_loss 7.5170161284898445 \n","trained  11\n","started_training\n","epoch 1 epoch_loss 0.062252602816836256 val_loss 7.550059309523356 \n","trained  12\n","started_training\n","epoch 1 epoch_loss 0.0622551800632799 val_loss 7.547508732660821 \n","trained  13\n","started_training\n","epoch 1 epoch_loss 0.0621368580976048 val_loss 7.539610556081722 \n","trained  14\n","started_training\n","epoch 1 epoch_loss 0.06215027271694428 val_loss 7.5596121096689455 \n","trained  15\n","started_training\n","epoch 1 epoch_loss 0.06256863298649723 val_loss 7.574420312909703 \n","trained  16\n","started_training\n","epoch 1 epoch_loss 0.0624874222620919 val_loss 7.5723815950516045 \n","trained  17\n","started_training\n","epoch 1 epoch_loss 0.0626114073738053 val_loss 7.580782249962031 \n","trained  18\n","started_training\n","epoch 1 epoch_loss 0.0626499287884783 val_loss 7.56789635533565 \n","trained  19\n","started_training\n","epoch 1 epoch_loss 0.06295188360318944 val_loss 7.586449190189963 \n","trained  20\n","started_training\n","epoch 1 epoch_loss 0.06281353790010955 val_loss 7.603714845878513 \n","trained  21\n","started_training\n","epoch 1 epoch_loss 0.06305815707388762 val_loss 7.634076595698532 \n","trained  22\n","started_training\n","epoch 1 epoch_loss 0.0631814711299297 val_loss 7.646117010594981 \n","trained  23\n","started_training\n","epoch 1 epoch_loss 0.06338529026991613 val_loss 7.626329094955797 \n","trained  24\n","started_training\n","epoch 1 epoch_loss 0.06322326767887618 val_loss 7.626247418554206 \n","trained  25\n","started_training\n","epoch 1 epoch_loss 0.06358148801971127 val_loss 7.6317702527893205 \n","trained  26\n","started_training\n","epoch 1 epoch_loss 0.06364059407968779 val_loss 7.644317886154902 \n","trained  27\n","started_training\n","epoch 1 epoch_loss 0.06386581828465333 val_loss 7.67260243763265 \n","trained  28\n","started_training\n","epoch 1 epoch_loss 0.06407439673470484 val_loss 7.676679739042335 \n","trained  29\n","started_training\n","epoch 1 epoch_loss 0.06382902384408422 val_loss 7.669628546426172 \n","trained  30\n","started_training\n","epoch 1 epoch_loss 0.06400158397249274 val_loss 7.688220165473849 \n","trained  31\n","started_training\n","epoch 1 epoch_loss 0.06382253489180191 val_loss 7.669938968788634 \n","trained  32\n","started_training\n","epoch 1 epoch_loss 0.06446649964798142 val_loss 7.727736555432017 \n","trained  33\n","started_training\n","epoch 1 epoch_loss 0.06408109933741994 val_loss 7.682890725959289 \n","trained  34\n","started_training\n","epoch 1 epoch_loss 0.06448992528021336 val_loss 7.706998927812827 \n","trained  35\n","started_training\n","epoch 1 epoch_loss 0.0644116225979618 val_loss 7.714678552197783 \n","trained  36\n","started_training\n","epoch 1 epoch_loss 0.06435176594233191 val_loss 7.6922732779854215 \n","trained  37\n","started_training\n","epoch 1 epoch_loss 0.06469718296382879 val_loss 7.72090183178845 \n","trained  38\n","started_training\n","epoch 1 epoch_loss 0.06460661154139687 val_loss 7.719468748491061 \n","trained  39\n","started_training\n","epoch 1 epoch_loss 0.064647672848927 val_loss 7.758838672975172 \n","trained  40\n","started_training\n","epoch 1 epoch_loss 0.06527428741793374 val_loss 7.758947025200252 \n","trained  41\n","started_training\n","epoch 1 epoch_loss 0.06474624146279451 val_loss 7.738177883193681 \n","trained  42\n","started_training\n","epoch 1 epoch_loss 0.06558168266673346 val_loss 7.775966931526599 \n","trained  43\n","started_training\n","epoch 1 epoch_loss 0.06544772973535834 val_loss 7.782864335532253 \n","trained  44\n","started_training\n","epoch 1 epoch_loss 0.06486779224832316 val_loss 7.746946567571478 \n","trained  45\n","started_training\n","epoch 1 epoch_loss 0.06502984932346924 val_loss 7.7550080206833405 \n","trained  46\n","started_training\n","epoch 1 epoch_loss 0.0648940764870998 val_loss 7.733655563898776 \n","trained  47\n","started_training\n","epoch 1 epoch_loss 0.06521943619323743 val_loss 7.769616960498846 \n","trained  48\n","started_training\n","epoch 1 epoch_loss 0.06517298489406302 val_loss 7.766424910214387 \n","trained  49\n","started_training\n","epoch 1 epoch_loss 0.06556039228028543 val_loss 7.780630651665361 \n","trained  50\n","started_training\n","epoch 1 epoch_loss 0.06555067989471797 val_loss 7.801795675958456 \n","trained  51\n","started_training\n","epoch 1 epoch_loss 0.06490584115522939 val_loss 7.750547140836714 \n","trained  52\n","started_training\n","epoch 1 epoch_loss 0.06553485853647864 val_loss 7.788897040643191 \n","trained  53\n","started_training\n","epoch 1 epoch_loss 0.06539181438652245 val_loss 7.773527377530148 \n","trained  54\n","started_training\n","epoch 1 epoch_loss 0.06517163840298718 val_loss 7.764086586864369 \n","trained  55\n","started_training\n","epoch 1 epoch_loss 0.06549883246220448 val_loss 7.78660865892705 \n","trained  56\n","started_training\n","epoch 1 epoch_loss 0.06544750521110522 val_loss 7.782814603102837 \n","trained  57\n","started_training\n","epoch 1 epoch_loss 0.06517541015873084 val_loss 7.759070637979009 \n","trained  58\n","started_training\n","epoch 1 epoch_loss 0.06532562247200592 val_loss 7.772850319351023 \n","trained  59\n","started_training\n","epoch 1 epoch_loss 0.06565386046831673 val_loss 7.7878080837820685 \n","trained  60\n","started_training\n","epoch 1 epoch_loss 0.0655785755732575 val_loss 7.805031002744249 \n","trained  61\n","started_training\n","epoch 1 epoch_loss 0.06546934814871969 val_loss 7.786229719260806 \n","trained  62\n","started_training\n","epoch 1 epoch_loss 0.06554681188552766 val_loss 7.8169228693372315 \n","trained  63\n","started_training\n","epoch 1 epoch_loss 0.06620121480443993 val_loss 7.7977671605583865 \n","trained  64\n","started_training\n","epoch 1 epoch_loss 0.0657051735733812 val_loss 7.8257858196371455 \n","trained  65\n","started_training\n","epoch 1 epoch_loss 0.0658995210117585 val_loss 7.817121307512648 \n","trained  66\n","started_training\n","epoch 1 epoch_loss 0.06551678191769768 val_loss 7.791196536076698 \n","trained  67\n","started_training\n","epoch 1 epoch_loss 0.06554448916702657 val_loss 7.786544435902644 \n","trained  68\n","started_training\n","epoch 1 epoch_loss 0.06608387999035217 val_loss 7.806355926747385 \n","trained  69\n","started_training\n","epoch 1 epoch_loss 0.06571117214657166 val_loss 7.812758151245746 \n","trained  70\n","started_training\n","epoch 1 epoch_loss 0.06553572718356107 val_loss 7.792149021437296 \n","trained  71\n","started_training\n","epoch 1 epoch_loss 0.06522481022654353 val_loss 7.77614572781481 \n","trained  72\n","started_training\n","epoch 1 epoch_loss 0.06548568042548927 val_loss 7.777763751188392 \n","trained  73\n","started_training\n","epoch 1 epoch_loss 0.06533510892375095 val_loss 7.780135041985073 \n","trained  74\n","started_training\n","epoch 1 epoch_loss 0.06541284022701753 val_loss 7.784106538483973 \n","trained  75\n","started_training\n","epoch 1 epoch_loss 0.06565151278030228 val_loss 7.803682907435455 \n","trained  76\n","started_training\n","epoch 1 epoch_loss 0.06532565504312515 val_loss 7.762397049681135 \n","trained  77\n","started_training\n","epoch 1 epoch_loss 0.0660137030220515 val_loss 7.847508089322794 \n","trained  78\n","started_training\n","epoch 1 epoch_loss 0.06567875260638224 val_loss 7.830058938774625 \n","trained  79\n","started_training\n","epoch 1 epoch_loss 0.0656700534494342 val_loss 7.784117499464436 \n","trained  80\n","started_training\n","epoch 1 epoch_loss 0.0653905381222029 val_loss 7.798901604586526 \n","trained  81\n","started_training\n","epoch 1 epoch_loss 0.065719648792937 val_loss 7.789520264260076 \n","trained  82\n","started_training\n","epoch 1 epoch_loss 0.06594998409619203 val_loss 7.7995967639512145 \n","trained  83\n","started_training\n","epoch 1 epoch_loss 0.06566704341487305 val_loss 7.790959986416918 \n","trained  84\n","started_training\n","epoch 1 epoch_loss 0.06613341643399484 val_loss 7.832432541015902 \n","trained  85\n","started_training\n","epoch 1 epoch_loss 0.06543275869980052 val_loss 7.797570937754292 \n","trained  86\n","started_training\n","epoch 1 epoch_loss 0.06551472898069266 val_loss 7.8191687615686325 \n","trained  87\n","started_training\n","epoch 1 epoch_loss 0.06622652764860038 val_loss 7.8238819770907115 \n","trained  88\n","started_training\n","epoch 1 epoch_loss 0.06555951557852127 val_loss 7.783407577362495 \n","trained  89\n","started_training\n","epoch 1 epoch_loss 0.06551037129719516 val_loss 7.785441762522647 \n","trained  90\n","started_training\n","epoch 1 epoch_loss 0.06589159601040788 val_loss 7.808741306591976 \n","trained  91\n","started_training\n","epoch 1 epoch_loss 0.06568369334815322 val_loss 7.81569436447401 \n","trained  92\n","started_training\n","epoch 1 epoch_loss 0.06582905472935857 val_loss 7.822395267651268 \n","trained  93\n","started_training\n","epoch 1 epoch_loss 0.06566013566948273 val_loss 7.791891770535394 \n","trained  94\n","started_training\n","epoch 1 epoch_loss 0.06574947135271253 val_loss 7.785324971338637 \n","trained  95\n","started_training\n","epoch 1 epoch_loss 0.06556992841934836 val_loss 7.807880726691924 \n","trained  96\n","started_training\n","epoch 1 epoch_loss 0.06563251561208351 val_loss 7.790541145754489 \n","trained  97\n","started_training\n","epoch 1 epoch_loss 0.0656495862514586 val_loss 7.797656093969156 \n","trained  98\n","started_training\n","epoch 1 epoch_loss 0.06547503304239866 val_loss 7.792902502182284 \n","trained  99\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXIAAAEQCAYAAACtGP9YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:09:50.788986Z","start_time":"2020-03-01T06:03:27.755529Z"},"id":"SjoAkUi7wHkr","colab_type":"code","colab":{}},"source":["%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DuQnTY34wHky","colab_type":"code","colab":{}},"source":["test_recall_100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-16T05:14:36.630878Z","start_time":"2019-11-16T05:14:36.599348Z"},"id":"-vjuwM1SwHk6","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), 'model5.pt')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-16T09:14:54.004905Z","start_time":"2019-11-16T09:14:53.947593Z"},"id":"IHawopbKwHlH","colab_type":"code","colab":{}},"source":["model.load_state_dict(torch.load('model6.pt'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T10:31:02.092246Z","start_time":"2019-11-13T10:30:58.186444Z"},"id":"eYHNL3q0wHlR","colab_type":"code","colab":{}},"source":["val_loss=evaluate(model, val_iter,criterion)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T10:31:07.335210Z","start_time":"2019-11-13T10:31:07.329855Z"},"id":"645035ynwHlY","colab_type":"code","colab":{}},"source":["val_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T08:37:36.469544Z","start_time":"2019-11-13T08:37:36.464199Z"},"id":"YBSQT9qEwHlg","colab_type":"code","colab":{}},"source":["len(train_iter)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T05:28:48.412253Z","start_time":"2019-11-13T05:28:47.507Z"},"id":"HOV8R1GswHlp","colab_type":"code","colab":{}},"source":["%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T05:28:48.412865Z","start_time":"2019-11-13T05:28:47.562Z"},"id":"DcZa1YnAwHlw","colab_type":"code","colab":{}},"source":["\n","class LSTMNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n","        super(LSTMNet, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","        \n","        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.relu = nn.ReLU()\n","        \n","    def forward(self, x, h):\n","        out, h = self.lstm(x, h)\n","        out = self.fc(self.relu(out[:,-1]))\n","        return out, h\n","    \n","    def init_hidden(self, batch_size):\n","        weight = next(self.parameters()).data\n","        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n","                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T05:17:09.166480Z","start_time":"2019-11-13T05:17:09.158065Z"},"id":"XsjTeDGpwHmQ","colab_type":"code","colab":{}},"source":["def train(train_loader, learn_rate, hidden_dim=256, EPOCHS=5, model_type=\"GRU\"):\n","    \n","    # Setting common hyperparameters\n","    input_dim = next(iter(train_loader))[0].shape[2]\n","    output_dim = input_dim\n","    n_layers = 1\n","    # Instantiating the models\n","    if model_type == \"GRU\":\n","        model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n","    else:\n","        model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n","    model.to(device)\n","    \n","    # Defining loss function and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n","    \n","    model.train()\n","    print(\"Starting Training of {} model\".format(model_type))\n","    epoch_times = []\n","    # Start training loop\n","    for epoch in range(1,EPOCHS+1):\n","        start_time = time.clock()\n","        h = model.init_hidden(batch_size)\n","        avg_loss = 0.\n","        counter = 0\n","        for x, label in train_loader:\n","            counter += 1\n","            if model_type == \"GRU\":\n","                h = h.data\n","            else:\n","                h = tuple([e.data for e in h])\n","            model.zero_grad()\n","            \n","            out, h = model(x.to(device).float(), h)\n","            loss = criterion(out, label.to(device).float())\n","            loss.backward()\n","            optimizer.step()\n","            avg_loss += loss.item()\n","            if counter%200 == 0:\n","                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n","        current_time = time.clock()\n","        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss/len(train_loader)))\n","        print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n","        epoch_times.append(current_time-start_time)\n","    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n","    return model\n","\n","def evaluate(model, test_x, test_y, label_scalers):\n","    model.eval()\n","    outputs = []\n","    targets = []\n","    start_time = time.clock()\n","    for i in test_x.keys():\n","        inp = torch.from_numpy(np.array(test_x[i]))\n","        labs = torch.from_numpy(np.array(test_y[i]))\n","        h = model.init_hidden(inp.shape[0])\n","        out, h = model(inp.to(device).float(), h)\n","        outputs.append(label_scalers[i].inverse_transform(out.cpu().detach().numpy()).reshape(-1))\n","        targets.append(label_scalers[i].inverse_transform(labs.numpy()).reshape(-1))\n","    print(\"Evaluation Time: {}\".format(str(time.clock()-start_time)))\n","    sMAPE = 0\n","    for i in range(len(outputs)):\n","        sMAPE += np.mean(abs(outputs[i]-targets[i])/(targets[i]+outputs[i])/2)/len(outputs)\n","    print(\"sMAPE: {}%\".format(sMAPE*100))\n","    return outputs, targets, sMAPE"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-13T05:17:09.257167Z","start_time":"2019-11-13T05:17:09.227553Z"},"id":"IrQLgBJ-wHma","colab_type":"code","colab":{}},"source":["new_array = np.array([1.2, 3.4, 5.6])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T15:33:37.253624Z","start_time":"2019-11-12T15:33:37.250752Z"},"id":"JVMp1pEFwHmj","colab_type":"code","colab":{}},"source":["train_ds[0].label.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:00:35.532459Z","start_time":"2020-03-01T07:00:35.529729Z"},"id":"eSXFXkMBwHmp","colab_type":"code","colab":{}},"source":["x = BucketIterator(train_ds, batch_size=4, sort_key='length')\n","# for y in x:\n","#     y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:01:30.902589Z","start_time":"2020-03-01T07:01:30.896798Z"},"id":"rQOfduDjwHmx","colab_type":"code","colab":{}},"source":["x.create_batches"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T06:55:56.564865Z","start_time":"2020-03-01T06:55:06.289292Z"},"id":"mQqWbVyewHm3","colab_type":"code","colab":{}},"source":["%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:37:57.783512Z","start_time":"2020-03-01T07:37:57.652924Z"},"id":"UFSIaOcJwHm-","colab_type":"code","colab":{}},"source":["train_ds= DataFrameDataset(fields= fields, examples=train.iloc[:1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:37:58.724364Z","start_time":"2020-03-01T07:37:58.718163Z"},"id":"eisTBHhXwHnE","colab_type":"code","colab":{}},"source":["y = BucketIterator(train_ds, batch_size=2,sort_key='length')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:37:59.618216Z","start_time":"2020-03-01T07:37:59.599209Z"},"id":"aUnTSVs1wHnL","colab_type":"code","colab":{}},"source":["for x in y:\n","    print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-01T07:44:32.007317Z","start_time":"2020-03-01T07:39:44.358986Z"},"scrolled":true,"id":"muOo1CDOwHnS","colab_type":"code","colab":{}},"source":["# train\n","%debug"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2020-03-01T08:06:36.142Z"},"id":"e3WKSeTcwHna","colab_type":"code","colab":{}},"source":["x =torch.randn((3,8199))\n","model(x,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpMINSv4wHno","colab_type":"code","colab":{}},"source":["10 epochs : 0.55(100) , 0.4(60)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gfvp4TtFwHnt","colab_type":"code","colab":{}},"source":["len(train_iter.dataset.examples)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwaU19_xwHn0","colab_type":"code","colab":{}},"source":["measures = defaultdict(lambda: defaultdict(list))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8h8krEgwHn6","colab_type":"code","colab":{}},"source":["measures[1]['11'].append('5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"58qwgdeewHoC","colab_type":"code","colab":{}},"source":["measures"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WcqiFBc7wHoI","colab_type":"code","colab":{}},"source":["(final_df2.iloc[:]['input'].apply(lambda x: max([max(y) for y in x])) )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8LrFOobwHoP","colab_type":"code","colab":{}},"source":["len(train_ds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zk-P6J2ty2Z3","colab_type":"code","colab":{}},"source":["np.arange(1,losses['train']+1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwTQVApXz8QD","colab_type":"code","colab":{}},"source":["for batch in train_iter:\n","  print(f'batch.input.shape  {batch.input.shape}  batch.label.shape {batch.label.shape}' ) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAZfX8G9Y9A3","colab_type":"code","colab":{}},"source":["for sample in train_ds.examples:\n","  if sample.input.shape[0] != sample.label.shape[0]:\n","    print(f'{sample.input.shape[0]} {sample.label.shape[0]} {sample.length}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"37jUnzYZZV3h","colab_type":"code","colab":{}},"source":["from pathlib import Path\n","\n","files = [x for x in filter(lambda x:x.split(\"_\")[0] == 'diagnosis', files)]\n","x = Path((os.path.join(\"SG\",(files[0]).split('_')[0]+'/'+ (files[0]).split('_')[3].split('.')[0])))\n","x\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"169c--HOtK0i","colab_type":"code","colab":{}},"source":["\n","# files"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7hipK5S2Wd0","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mcX8Nnsk2XnP","colab_type":"code","colab":{}},"source":["device"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3nWeP2wm7RY4","colab_type":"code","colab":{}},"source":["x = model.embedding.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ualTzhTL9Op4","colab_type":"code","colab":{}},"source":["x.weight"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fEPBjVu9ePx","colab_type":"code","colab":{}},"source":["model.embedding.weight.device"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uhAvvIL_UpC","colab_type":"code","outputId":"6c00fc0c-acf4-4d3b-bc5b-9947649811f0","executionInfo":{"status":"ok","timestamp":1583221180221,"user_tz":-330,"elapsed":6262,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["final_df2[final_df2.label.apply(lambda x: sum([False if z.shape!=2806 else True for y in x for z in y])) != 0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>label</th>\n","      <th>length</th>\n","    </tr>\n","    <tr>\n","      <th>SUBJECT_ID</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [input, label, length]\n","Index: []"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"Tss8enccTz0i","colab_type":"code","outputId":"3f3d37b9-6a36-4713-a109-a2f5b00857d5","executionInfo":{"status":"ok","timestamp":1583221431649,"user_tz":-330,"elapsed":709,"user":{"displayName":"sai teja","photoUrl":"","userId":"16594513689443432198"}},"colab":{"base_uri":"https://localhost:8080/","height":455}},"source":["final_df2[final_df2.input.apply(lambda x: sum([False if len(y)!=1324 else True for y in x ])) == 0]\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>label</th>\n","      <th>length</th>\n","    </tr>\n","    <tr>\n","      <th>SUBJECT_ID</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0,...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99822</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0,...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>99883</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99897</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99923</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99982</th>\n","      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n","      <td>[[0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0,...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6515 rows  3 columns</p>\n","</div>"],"text/plain":["                                                        input  ... length\n","SUBJECT_ID                                                     ...       \n","17          [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      1\n","21          [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      1\n","23          [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      1\n","34          [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      1\n","36          [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      2\n","...                                                       ...  ...    ...\n","99822       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      2\n","99883       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      1\n","99897       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      1\n","99923       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      1\n","99982       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  ...      2\n","\n","[6515 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"mYAkDrZBV1ky","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}